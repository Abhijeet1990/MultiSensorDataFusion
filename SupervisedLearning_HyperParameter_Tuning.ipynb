{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def getFilePath(os,poll_rate,use_case,location):\n",
    "    common_path = '../data/'\n",
    "    if os==10 and poll_rate ==60 and usecase=='UC1':\n",
    "        path='csvs/UC1/'+location+'_merged_phy_cyb_10os_60poll_encoded.csv'\n",
    "        adv_path='Adversary/UC1_PyDNP3_CORE_Adversary_10_OS_60_dnp3.json'\n",
    "    elif os==10 and poll_rate ==30 and usecase=='UC1':\n",
    "        path='csvs/UC1/'+location+'_merged_phy_cyb_10os_30poll_encoded.csv'\n",
    "        adv_path='Adversary/UC1_PyDNP3_CORE_Adversary_10_OS_30_dnp3.json'\n",
    "    elif os==5 and poll_rate ==30 and usecase=='UC2':\n",
    "        path='csvs/UC2/uc2_'+location+'_merged_phy_cyb_5os_30poll_encoded.csv'\n",
    "        adv_path='Adversary/UC2_PyDNP3_CORE_Adversary_5_OS_30_dnp3.json'\n",
    "    elif os==5 and poll_rate ==60 and usecase=='UC2':\n",
    "        path='csvs/UC2/uc2_'+location+'_merged_phy_cyb_5os_60poll_encoded.csv'\n",
    "        adv_path='Adversary/UC2_PyDNP3_CORE_Adversary_5_OS_60_dnp3.json'\n",
    "    elif os==10 and poll_rate ==30 and usecase=='UC2':\n",
    "        path='csvs/UC2/uc2_'+location+'_merged_phy_cyb_10os_30poll_encoded.csv'\n",
    "        adv_path='Adversary/UC2_PyDNP3_CORE_Adversary_10_OS_30_dnp3.json'\n",
    "    elif os==10 and poll_rate ==60 and usecase=='UC2':\n",
    "        path='csvs/UC2/uc2_'+location+'_merged_phy_cyb_10os_60poll_encoded.csv'\n",
    "        adv_path='Adversary/UC2_PyDNP3_CORE_Adversary_10_OS_60_dnp3.json'\n",
    "    elif os==5 and poll_rate ==30 and usecase=='UC3':\n",
    "        path='csvs/UC3/uc3_'+location+'_merged_phy_cyb_5os_30poll_encoded.csv'\n",
    "        adv_path='Adversary/UC3_PyDNP3_CORE_Adversary_5_OS_30_dnp3.json'\n",
    "    elif os==5 and poll_rate ==60 and usecase=='UC3':\n",
    "        path='csvs/UC3/uc3_'+location+'_merged_phy_cyb_5os_60poll_encoded.csv'\n",
    "        adv_path='Adversary/UC3_PyDNP3_CORE_Adversary_5_OS_60_dnp3.json'\n",
    "    elif os==10 and poll_rate ==30 and usecase=='UC3':\n",
    "        path='csvs/UC3/uc3_'+location+'_merged_phy_cyb_10os_30poll_encoded.csv'\n",
    "        adv_path='Adversary/UC3_PyDNP3_CORE_Adversary_10_OS_30_dnp3.json'\n",
    "    elif os==10 and poll_rate ==60 and usecase=='UC3':\n",
    "        path='csvs/UC3/uc3_'+location+'_merged_phy_cyb_10os_60poll_encoded.csv'\n",
    "        adv_path='Adversary/UC3_PyDNP3_CORE_Adversary_10_OS_60_dnp3.json'\n",
    "    elif os==5 and poll_rate ==30 and usecase=='UC4':\n",
    "        path='csvs/UC4/uc4_'+location+'_merged_phy_cyb_5os_30poll_encoded.csv'\n",
    "        adv_path='Adversary/UC4_PyDNP3_CORE_Adversary_5_OS_30_dnp3.json'\n",
    "    elif os==5 and poll_rate ==60 and usecase=='UC4':\n",
    "        path='csvs/UC4/uc4_'+location+'_merged_phy_cyb_5os_60poll_encoded.csv'\n",
    "        adv_path='Adversary/UC4_PyDNP3_CORE_Adversary_5_OS_60_dnp3.json'\n",
    "    elif os==10 and poll_rate ==30 and usecase=='UC4':\n",
    "        path='csvs/UC4/uc4_'+location+'_merged_phy_cyb_10os_30poll_encoded.csv'\n",
    "        adv_path='Adversary/UC4_PyDNP3_CORE_Adversary_10_OS_30_dnp3.json'\n",
    "    elif os==10 and poll_rate ==60 and usecase=='UC4':\n",
    "        path='csvs/UC4/uc4_'+location+'_merged_phy_cyb_10os_60poll_encoded.csv'\n",
    "        adv_path='Adversary/UC4_PyDNP3_CORE_Adversary_10_OS_60_dnp3.json'\n",
    "    return common_path+path,common_path+adv_path\n",
    "\n",
    "from DataFusion import DataFusion\n",
    "import time\n",
    "import datetime\n",
    "def get_intrusion_window(adversary_path):\n",
    "    fusion = DataFusion()\n",
    "    fusion.load_json(adversary_path)\n",
    "    fusion.extract_cyber_data()\n",
    "    fusion.extract_physical_data()\n",
    "    data_to_process = fusion.merge()\n",
    "    attack_start = data_to_process.iloc[0]['Time']\n",
    "    start = int(time.mktime(attack_start.timetuple()))\n",
    "    attack_end = data_to_process.iloc[-1]['Time']\n",
    "    end = int(time.mktime(attack_end.timetuple()))\n",
    "    return start,end\n",
    "\n",
    "def process_label(data,start_time,end_time):\n",
    "    #data.drop('Unnamed:0',1)\n",
    "    data = data.drop(data.columns[[0]], axis=1)\n",
    "    data['DNP3 Objects'].replace('None', np.nan, inplace=True)\n",
    "\n",
    "    replace_map = dict([('DNP3 Objects',0),('value1', 0.0), ('value2', 0.0), ('value3', 0.0), \n",
    "                   ('value4', 0.0),('value5',0.0)])\n",
    "\n",
    "    # fill nan by replace values\n",
    "    data = data.fillna(value=replace_map)\n",
    "    data.head()\n",
    "\n",
    "    data['Time'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "    data['Label'] = 0\n",
    "    for i,val in data.iterrows():\n",
    "        unix_time = int(time.mktime(val['Time'].timetuple()))\n",
    "        if unix_time <end_time and unix_time>start_time:\n",
    "            data['Label'][i] = 1\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "location = 'DS'\n",
    "usecase='UC1'\n",
    "os=10\n",
    "poll_rate = 30\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC1'\n",
    "os=10\n",
    "poll_rate = 60\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data2 = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC2'\n",
    "os=5\n",
    "poll_rate = 30\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data3 = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC2'\n",
    "os=5\n",
    "poll_rate = 60\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data4 = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC2'\n",
    "os=10\n",
    "poll_rate = 30\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data5 = process_label(data,start_time,end_time)\n",
    "\n",
    "\n",
    "usecase='UC2'\n",
    "os=10\n",
    "poll_rate =60\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data6 = process_label(data,start_time,end_time)\n",
    "\n",
    "\n",
    "usecase='UC3'\n",
    "os=5\n",
    "poll_rate =30\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data7 = process_label(data,start_time,end_time)\n",
    "\n",
    "\n",
    "usecase='UC3'\n",
    "os=5\n",
    "poll_rate =60\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data8 = process_label(data,start_time,end_time)\n",
    "\n",
    "\n",
    "usecase='UC3'\n",
    "os=10\n",
    "poll_rate =30\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data9 = process_label(data,start_time,end_time)\n",
    "\n",
    "\n",
    "usecase='UC3'\n",
    "os=10\n",
    "poll_rate =60\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data10 = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC4'\n",
    "os=5\n",
    "poll_rate =30\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data11 = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC4'\n",
    "os=5\n",
    "poll_rate =60\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data12 = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC4'\n",
    "os=10\n",
    "poll_rate =30\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data13 = process_label(data,start_time,end_time)\n",
    "\n",
    "usecase='UC4'\n",
    "os=10\n",
    "poll_rate =60\n",
    "path,adv_path=getFilePath(os,poll_rate,usecase,location)\n",
    "data = pd.read_csv(path)\n",
    "start_time,end_time = get_intrusion_window(adv_path)\n",
    "new_data14 = process_label(data,start_time,end_time)\n",
    "\n",
    "#frames = [new_data,new_data2,new_data3,new_data4,new_data5,new_data6,new_data7,new_data8,new_data9,new_data10,new_data11,new_data12,new_data13,new_data14]\n",
    "frames = [new_data14]\n",
    "res = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "replace_map = dict([('DNP3 Objects',0),('value1', 0.0), ('value2', 0.0), ('value3', 0.0), \n",
    "                   ('value4', 0.0),('value5',0.0)])\n",
    "\n",
    "# fill nan by replace values\n",
    "res = res.fillna(value=replace_map)\n",
    "\n",
    "# compute the feature table\n",
    "feature_table = res.drop(columns=['Time', 'snort_alert', 'snort_alert_type','Label'])\n",
    "\n",
    "feature_array = feature_table.to_numpy()\n",
    "label_array = res[['Label']].to_numpy().flatten()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_array, label_array, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid_search_knn = GridSearchCV( KNeighborsClassifier(), param_grid, cv=10, scoring='accuracy')\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.82\n",
      "Confusion Matrix :\n",
      "[[11  6]\n",
      " [ 3 31]]\n",
      "Accuracy Score :0.8235294117647058\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71        17\n",
      "           1       0.84      0.91      0.87        34\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.81      0.78      0.79        51\n",
      "weighted avg       0.82      0.82      0.82        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, predictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "results = confusion_matrix(y_test, predictions) \n",
    "  \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :'+str(accuracy_score(y_test,predictions)))\n",
    "print('Report : ')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 140 candidates, totalling 420 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'degree': [0, 1, 2, 3, 4, 5, 6],\n",
       "                         'gamma': [0.1, 1, 10, 100]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "params = {'degree': [0,1,2,3,4,5,6], 'C': [0.1,1,10,100,1000], 'gamma': [0.1, 1, 10, 100]}\n",
    "grid_search_cv = GridSearchCV(svm.SVC(kernel='rbf'), params, verbose=1, cv=3)\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, degree=0, gamma=0.1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.67\n",
      "Confusion Matrix :\n",
      "[[ 0 17]\n",
      " [ 0 34]]\n",
      "Accuracy Score :0.6666666666666666\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.67      1.00      0.80        34\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.33      0.50      0.40        51\n",
      "weighted avg       0.44      0.67      0.53        51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf',C=.1, degree=0, gamma=.1)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, predictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "results = confusion_matrix(y_test, predictions) \n",
    "  \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :'+str(accuracy_score(y_test,predictions)))\n",
    "print('Report : ')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4704 candidates, totalling 14112 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_leaf_nodes=5, random_state=9999)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "params = {'criterion': ['gini', 'entropy'],'max_depth': [1, 2, 3, 4, 5, 6, 7, 8],'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(tree.DecisionTreeClassifier(random_state=9999), params, verbose=1, cv=3)\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.96\n",
      "Confusion Matrix :\n",
      "[[17  0]\n",
      " [ 4 30]]\n",
      "Accuracy Score :0.9215686274509803\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        17\n",
      "           1       1.00      0.88      0.94        34\n",
      "\n",
      "    accuracy                           0.92        51\n",
      "   macro avg       0.90      0.94      0.92        51\n",
      "weighted avg       0.94      0.92      0.92        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(criterion='entropy',max_depth=2, max_leaf_nodes=3, random_state=9999)\n",
    "dt.fit(X_train, y_train)\n",
    "dtpredictions = dt.predict(X_test)\n",
    "\n",
    "average_precision = average_precision_score(y_test, dtpredictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "disp = plot_precision_recall_curve(dt, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "\n",
    "results = confusion_matrix(y_test, dtpredictions) \n",
    "  \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :'+str(accuracy_score(y_test,dtpredictions)))\n",
    "print('Report : ')\n",
    "print(classification_report(y_test,dtpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params= {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(random_state=42), params, verbose=1, cv=3)\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=80, max_features=3, min_samples_leaf=3,min_samples_split=8, n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rfpredictions = rf.predict(X_test)\n",
    "\n",
    "average_precision = average_precision_score(y_test, rfpredictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "disp = plot_precision_recall_curve(rf, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "\n",
    "results = confusion_matrix(y_test, rfpredictions) \n",
    "  \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :'+str(accuracy_score(y_test,rfpredictions)))\n",
    "print('Report : ')\n",
    "print(classification_report(y_test,rfpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=GaussianNB(), \n",
    "                     param_grid=params_NB, \n",
    "                     verbose=1, \n",
    "                     scoring='accuracy')\n",
    "gs_NB.fit(X_train, y_train)\n",
    "gs_NB.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB(var_smoothing=0.0002310129700083158)\n",
    "gnb.fit(X_train, y_train)\n",
    "gnbpredictions = gnb.predict(X_test)\n",
    "\n",
    "average_precision = average_precision_score(y_test, gnbpredictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "disp = plot_precision_recall_curve(gnb, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "\n",
    "results = confusion_matrix(y_test, gnbpredictions) \n",
    "  \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :'+str(accuracy_score(y_test,gnbpredictions)))\n",
    "print('Report : ')\n",
    "print(classification_report(y_test,gnbpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]}\n",
    "\n",
    "bernoulli_nb_grid = GridSearchCV(BernoulliNB(), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
    "bernoulli_nb_grid.fit(X_train, y_train)\n",
    "bernoulli_nb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(alpha=0.5)\n",
    "bnb.fit(X_train, y_train)\n",
    "bnbpredictions = bnb.predict(X_test)\n",
    "\n",
    "average_precision = average_precision_score(y_test, bnbpredictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "disp = plot_precision_recall_curve(bnb, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "results = confusion_matrix(y_test, bnbpredictions) \n",
    "  \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :'+str(accuracy_score(y_test,bnbpredictions)))\n",
    "print('Report : ')\n",
    "print(classification_report(y_test,bnbpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(MLPClassifier(max_iter=100), param_grid=parameter_space)\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "mlp_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(10, 30, 10),learning_rate='adaptive', max_iter=100, solver='sgd')\n",
    "nn.fit(X_train, y_train)\n",
    "nnpredictions = nn.predict(X_test)\n",
    "\n",
    "average_precision = average_precision_score(y_test, nnpredictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "disp = plot_precision_recall_curve(nn, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(y_test, nnpredictions) \n",
    "  \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :'+str(accuracy_score(y_test,nnpredictions)))\n",
    "print('Report : ')\n",
    "print(classification_report(y_test,nnpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
